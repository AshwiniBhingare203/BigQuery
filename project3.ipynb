{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pyspark\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@udf('string')\n",
    "def munge_event(event_as_json):\n",
    "    event = json.loads(event_as_json)\n",
    "    event['Host'] = \"moe\" # silly change to show it works\n",
    "    event['Cache-Control'] = \"no-cache\"\n",
    "    return json.dumps(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+----+---------------+--------------+--------------------+\n",
      "|Accept|Cache-Control|Host|     User-Agent|    event_type|           timestamp|\n",
      "+------+-------------+----+---------------+--------------+--------------------+\n",
      "|   */*|     no-cache| moe|    curl/7.47.0|purchase_sword|2019-12-07 03:00:...|\n",
      "|   */*|     no-cache| moe|    curl/7.47.0|purchase_sword|2019-12-07 03:00:...|\n",
      "|   */*|     no-cache| moe|    curl/7.47.0|purchase_sword|2019-12-07 03:00:...|\n",
      "|   */*|     no-cache| moe|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|     no-cache| moe|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|     no-cache| moe|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|     no-cache| moe|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|     no-cache| moe|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|     no-cache| moe|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|     no-cache| moe|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|     no-cache| moe|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|     no-cache| moe|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|     no-cache| moe|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|     no-cache| moe|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|     no-cache| moe|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|     no-cache| moe|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|     no-cache| moe|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|     no-cache| moe|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|     no-cache| moe|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|     no-cache| moe|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "+------+-------------+----+---------------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------+-------------+----+----------+----------+---------+\n",
      "|Accept|Cache-Control|Host|User-Agent|event_type|timestamp|\n",
      "+------+-------------+----+----------+----------+---------+\n",
      "+------+-------------+----+----------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_events = spark \\\n",
    "        .read \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
    "        .option(\"subscribe\", \"events\") \\\n",
    "        .option(\"startingOffsets\", \"earliest\") \\\n",
    "        .option(\"endingOffsets\", \"latest\") \\\n",
    "        .load()\n",
    "\n",
    "munged_events = raw_events \\\n",
    "        .select(raw_events.value.cast('string').alias('raw'),\n",
    "                raw_events.timestamp.cast('string')) \\\n",
    "        .withColumn('munged', munge_event('raw'))\n",
    "\n",
    "extracted_events = munged_events \\\n",
    "        .rdd \\\n",
    "        .map(lambda r: Row(timestamp=r.timestamp, **json.loads(r.munged))) \\\n",
    "        .toDF()\n",
    "\n",
    "sword_purchases = extracted_events \\\n",
    "   .filter(extracted_events.event_type == 'purchase_sword')\n",
    "    \n",
    "sword_purchases.show()\n",
    "\n",
    "sword_purchases \\\n",
    "    .write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(\"/tmp/sword_purchases\")\n",
    "\n",
    "default_hits = extracted_events \\\n",
    "    .filter(extracted_events.event_type == 'default')\n",
    "    \n",
    "default_hits.show()\n",
    "\n",
    "default_hits \\\n",
    "        .write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .parquet(\"/tmp/default_hits\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Accept: string (nullable = true)\n",
      " |-- Host: string (nullable = true)\n",
      " |-- User-Agent: string (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      "\n",
      "+------+-----------------+---------------+--------------+--------------------+\n",
      "|Accept|             Host|     User-Agent|    event_type|           timestamp|\n",
      "+------+-----------------+---------------+--------------+--------------------+\n",
      "|   */*|   localhost:5000|    curl/7.47.0|purchase_sword|2019-12-07 03:00:...|\n",
      "|   */*|   localhost:5000|    curl/7.47.0|purchase_sword|2019-12-07 03:00:...|\n",
      "|   */*|   localhost:5000|    curl/7.47.0|purchase_sword|2019-12-07 03:00:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "|   */*|user1.comcast.com|ApacheBench/2.3|purchase_sword|2019-12-07 03:14:...|\n",
      "+------+-----------------+---------------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"Extract events from kafka and write them to hdfs\n",
    "\"\"\"\n",
    "import json\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "\n",
    "@udf('boolean')\n",
    "def is_purchase(event_as_json):\n",
    "    event = json.loads(event_as_json)\n",
    "    if event['event_type'] == 'purchase_sword':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"ExtractEventsJob\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "raw_events = spark \\\n",
    "    .read \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
    "    .option(\"subscribe\", \"events\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .option(\"endingOffsets\", \"latest\") \\\n",
    "    .load()\n",
    "\n",
    "purchase_events = raw_events \\\n",
    "    .select(raw_events.value.cast('string').alias('raw'),\n",
    "            raw_events.timestamp.cast('string')) \\\n",
    "    .filter(is_purchase('raw'))\n",
    "\n",
    "extracted_purchase_events = purchase_events \\\n",
    "    .rdd \\\n",
    "    .map(lambda r: Row(timestamp=r.timestamp, **json.loads(r.raw))) \\\n",
    "    .toDF()\n",
    "extracted_purchase_events.printSchema()\n",
    "extracted_purchase_events.show()\n",
    "\n",
    "extracted_purchase_events \\\n",
    "    .write \\\n",
    "    .mode('overwrite') \\\n",
    "    .parquet('/tmp/purchases')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import json\n",
    "from pyspark.sql.functions import udf, from_json\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "\n",
    "def purchase_sword_event_schema():\n",
    "    \"\"\"\n",
    "    root\n",
    "    |-- Accept: string (nullable = true)\n",
    "    |-- Host: string (nullable = true)\n",
    "    |-- User-Agent: string (nullable = true)\n",
    "    |-- event_type: string (nullable = true)\n",
    "    |-- timestamp: string (nullable = true)\n",
    "    \"\"\"\n",
    "    return StructType([\n",
    "        StructField(\"Accept\", StringType(), True),\n",
    "        StructField(\"Host\", StringType(), True),\n",
    "        StructField(\"User-Agent\", StringType(), True),\n",
    "        StructField(\"event_type\", StringType(), True),\n",
    "    ])\n",
    "\n",
    "\n",
    "@udf('boolean')\n",
    "def is_sword_purchase(event_as_json):\n",
    "    \"\"\"udf for filtering events\n",
    "    \"\"\"\n",
    "    event = json.loads(event_as_json)\n",
    "    if event['event_type'] == 'purchase_sword':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "raw_events = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
    "    .option(\"subscribe\", \"events\") \\\n",
    "    .load()\n",
    "\n",
    "sword_purchases = raw_events \\\n",
    "    .filter(is_sword_purchase(raw_events.value.cast('string'))) \\\n",
    "    .select(raw_events.value.cast('string').alias('raw_event'),\n",
    "            raw_events.timestamp.cast('string'),\n",
    "            from_json(raw_events.value.cast('string'),\n",
    "                      purchase_sword_event_schema()).alias('json')) \\\n",
    "    .select('raw_event', 'timestamp', 'json.*')\n",
    "\n",
    "sink = sword_purchases \\\n",
    "    .writeStream \\\n",
    "    .format(\"parquet\") \\\n",
    "    .option(\"checkpointLocation\", \"/tmp/checkpoints_for_sword_purchases\") \\\n",
    "    .option(\"path\", \"/tmp/sword_purchases\") \\\n",
    "    .trigger(processingTime=\"10 seconds\") \\\n",
    "    .start()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_string = \"drop table if exists default.hdfs_sword_purchase_events\"\n",
    "spark.sql(sql_string)\n",
    "sql_string = \"\"\"\n",
    "create external table if not exists default.hdfs_sword_purchase_events (\n",
    "    raw_event string,\n",
    "    timestamp string,\n",
    "    Accept string,\n",
    "    Host string,\n",
    "    `User-Agent` string,\n",
    "    event_type string\n",
    ") \n",
    "stored as parquet \n",
    "location '/tmp/sword_purchases'  \n",
    "tblproperties (\"parquet.compress\"=\"SNAPPY\")\n",
    "\"\"\"\n",
    "spark.sql(sql_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sink.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
